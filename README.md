# team-OrcaBox

**About**

Our tool is a web browser extension that is triggered once an image is clicked on, the image URL gets saved and then using Azure ComputerVision a text description of the image is generated. After this, we implemented Azure text-to-speech and used a couple of Azure functions to play the audio file generated from Azure through the extension so it can be heard by the user. The extension basically uses AI to describe what is happening in an image, then uses Azure services to generate an audio file that gets outputted by the extension. 

**Material**
Video Demo: https://www.youtube.com/watch?v=nmo-BexDSmE

(External viewers, please reach out for access)
Powerpoint: https://microsoft-my.sharepoint.com/:p:/p/t-williamtom/IQCNdL6n2LJHQaCLhuazGSt1AfvWF_25zdKVzMjbdmFapg4?e=LUm9IJ

Business Requirements Document: 

